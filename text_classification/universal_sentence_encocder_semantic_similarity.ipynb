{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "universal-sentence-encocder-semantic-similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRp5Fc16hK_Q"
      },
      "source": [
        "# TL;DR\n",
        "This notebook demonstrates how powerful sentence embeddings from Universal Sentence Encoder are.  \n",
        "These sentence representations can be used in varities of NLP tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0swKNFoohK_a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import nltk\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-t1tNSqCkPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e24c80d-944a-4b5f-8b40-2d4d71aee956"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86vn5vNChK_s"
      },
      "source": [
        "## Universal Sentence Encoder\n",
        "It is the model for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The model is efficient and result in accurate performance on diverse transfer tasks.  \n",
        "\n",
        "**References**  \n",
        "- [arxiv](https://arxiv.org/abs/1803.11175)\n",
        "- [tensorflow hub](https://tfhub.dev/google/universal-sentence-encoder-large/3)\n",
        "- [colab notebook](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb)\n",
        "- [my personal usecase](https://github.com/NISH1001/lyrics2vec/blob/master/lyrics2vec.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwHzpEZ2hK_w"
      },
      "source": [
        "### Load Embedding Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyx5ExWFhK_0"
      },
      "source": [
        "# https://github.com/NISH1001/machine-learning-into-the-void/blob/master/nlp/universal-sentence-encocder-semantic-similarity.ipynb\n",
        "# tensroflow hub module for Universal sentence Encoder\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8hMpPk-hLAB"
      },
      "source": [
        "embed = hub.Module(module_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N3iMx-khLAM"
      },
      "source": [
        "## Feature Extractor\n",
        "\n",
        "This is just a simple function to wrap tensorflow call.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnECGyihLAP"
      },
      "source": [
        "def get_features(texts):\n",
        "    if type(texts) is str:\n",
        "        texts = [texts]\n",
        "    with tf.Session() as sess:\n",
        "        sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        return sess.run(embed(texts))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O92E5d93hLAW"
      },
      "source": [
        "## Preprocess Textual Mess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyYPx-UwhLAY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b1c3d38-de9c-43aa-89e8-884266bf7df9"
      },
      "source": [
        "def remove_stopwords(stop_words, tokens):\n",
        "    res = []\n",
        "    for token in tokens:\n",
        "        if not token in stop_words:\n",
        "            res.append(token)\n",
        "    return res\n",
        "\n",
        "def process_text(text):\n",
        "    text = text.encode('ascii', errors='ignore').decode()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "    text = re.sub(r'#+', ' ', text )\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
        "    text = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", text)\n",
        "    #text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"won't\", \"will not \", text)\n",
        "    text = re.sub(r\"isn't\", \"is not \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "def lemmatize(tokens):\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    lemma_list = []\n",
        "    for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token, 'v')\n",
        "        if lemma == token:\n",
        "            lemma = lemmatizer.lemmatize(token)\n",
        "        lemma_list.append(lemma)\n",
        "    # return [ lemmatizer.lemmatize(token, 'v') for token in tokens ]\n",
        "    return lemma_list\n",
        "\n",
        "\n",
        "def process_all(text):\n",
        "    text = process_text(text)\n",
        "    return ' '.join(remove_stopwords(stop_words, text.split()))\n",
        "\n",
        "process_text(\"Hello! Who are you?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello who are you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsyBo454hLAe"
      },
      "source": [
        "## Load Data\n",
        "Here, I am using some dummy texts of mine.  \n",
        "Most of the data is taken from [here](https://github.com/NISH1001/rnn-for-text/blob/master/data/input.txt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK-xyIHShLAf"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/research_project/nlp_privacy_policy_analyze/data/Annotated_privacy_policy_segments_100.csv', encoding='utf-8')\n",
        "filtredData = df[df['annotated_class'] != 'OTHER']\n",
        "data = filtredData['statement']\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBO0BB-ahLAk"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZ20cGihLAl"
      },
      "source": [
        "data_processed = list(map(process_text, data))\n",
        "len(data_processed)\n",
        "data_processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLi7FFa2hLAp"
      },
      "source": [
        "#### Peek Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afhVnXyPhLAr"
      },
      "source": [
        "# peek \n",
        "[d[:100] for d in data_processed ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jql-aeUGhLAv"
      },
      "source": [
        "## Create Sentence Embedding\n",
        "Here, we use Universal Sentence Encoder to featurize each text.  \n",
        "This will create some type of representation of text in latent space.  \n",
        "The length of each vector is 512."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oLdTWZ5hLAw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c30fd1a1-3104-4187-d0d5-3a4c6bc48ec0"
      },
      "source": [
        "BASE_VECTORS = get_features(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP9V8pULhLAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47f3eacb-a8f9-4b61-a0e7-46be353cace7"
      },
      "source": [
        "BASE_VECTORS.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XITxHq-lhLA2"
      },
      "source": [
        "## Define Similarity Metric\n",
        "We use cosine similarity to find simiarity between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRqvGBMDhLA3"
      },
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    mag1 = np.linalg.norm(v1)\n",
        "    mag2 = np.linalg.norm(v2)\n",
        "    if (not mag1) or (not mag2):\n",
        "        return 0\n",
        "    return np.dot(v1, v2) / (mag1 * mag2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLI8hCfwhLA6"
      },
      "source": [
        "def test_similiarity(text1, text2):\n",
        "    vec1 = get_features(text1)[0]\n",
        "    vec2 = get_features(text2)[0]\n",
        "    print(vec1.shape)\n",
        "    return cosine_similarity(vec1, vec2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAM18wX-hLBH"
      },
      "source": [
        "## Semantic Matching/Search\n",
        "Use the data we defined earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5rAWZuIhLBI"
      },
      "source": [
        "def semantic_search(query, data, vectors):\n",
        "    query = process_text(query)\n",
        "    print(\"Extracting features...\")\n",
        "    query_vec = get_features(query)[0].ravel()\n",
        "    res = []\n",
        "    for i, d in enumerate(data):\n",
        "        qvec = vectors[i].ravel()\n",
        "        sim = cosine_similarity(query_vec, qvec)\n",
        "        res.append((sim, d[:100], i))\n",
        "    return sorted(res, key=lambda x : x[0], reverse=True)\n",
        "\n",
        "def semantic_search_requirements(query, data, vectors):\n",
        "    query = process_text(query)\n",
        "    print(\"Extracting features...\")\n",
        "    query_vec = get_features(query)[0].ravel()\n",
        "    res = []\n",
        "    for i, row in data.iterrows():\n",
        "        qvec = vectors[i].ravel()\n",
        "        sim = cosine_similarity(query_vec, qvec)\n",
        "        if(sim >= 0.5):\n",
        "          res.append((sim, row['clean_sentence'], row['annotated_class'], i))\n",
        "    return sorted(res, key=lambda x : x[0], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_WkRlPVhLBL"
      },
      "source": [
        "#### Query 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Xz2axKF7iJ"
      },
      "source": [
        "for i, row in filtredData.iterrows():\n",
        "  filtredData.at[i, 'clean_sentence'] = process_text(row['statement'])\n",
        "\n",
        "filtredData.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RfptzjehLBM"
      },
      "source": [
        "df_requirements = pd.read_csv('/content/drive/My Drive/research_project/nlp_privacy_policy_analyze/data/processed_privacy_policy_segments_sample_100_3.csv', encoding='utf-8')\n",
        "print(df_requirements)\n",
        "semantic_results = []\n",
        "for i, row in df_requirements.iterrows():\n",
        "  sentence = row['statement']\n",
        "  if(pd.notna(sentence) and sentence.strip() != \"\"):\n",
        "    print(row['statement'])\n",
        "    result = semantic_search_requirements(row['statement'], filtredData, BASE_VECTORS)\n",
        "    print(result)\n",
        "    df_requirements.at[i, 'semantic_similarity'] = str(result)\n",
        "    if result:\n",
        "      df_requirements.at[i, 'sim_class'] = str(result[0][2])\n",
        "  # semantic_results.append([df_requirements['id'][i], df_requirements['requirement'][i], result])\n",
        "#result_df = pd.DataFrame(semantic_results)\n",
        "\n",
        "df_requirements.to_csv('/content/drive/My Drive/research_project/nlp_privacy_policy_analyze/data/semenatic_sim_privacy_policy_segments_sample_100_3.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}