{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPolicyFile(fileLocation):\n",
    "    policySegments = []\n",
    "    for filename in os.listdir(fileLocation):\n",
    "        absFilename = \"{}/{}\".format(fileLocation,filename)\n",
    "        with open(absFilename) as csv_file:\n",
    "            #print absFilename\n",
    "            categoryId = 0\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                if row[5] == \"First Party Collection/Use\":\n",
    "                    categoryId = 1\n",
    "                elif row[5] == \"Third Party Sharing/Collection\":\n",
    "                    categoryId = 2\n",
    "                elif row[5] == \"User Choice/Control\":\n",
    "                    categoryId = 3\n",
    "                elif row[5] == \"User Access, Edit and Deletion\":\n",
    "                    categoryId = 4\n",
    "                elif row[5] == \"Data Retention\":\n",
    "                    categoryId = 5\n",
    "                elif row[5] == \"Data Security\":\n",
    "                    categoryId = 6\n",
    "                elif row[5] == \"Policy Change\":\n",
    "                    categoryId = 7\n",
    "                elif row[5] == \"Do Not Track\":\n",
    "                    categoryId = 8 \n",
    "                elif row[5] == \"International and Specific Audiences\":\n",
    "                    categoryId = 9\n",
    "                elif row[5] == \"Introductory/Generic\":\n",
    "                    categoryId = 10\n",
    "                elif row[5] == \"Privacy contact information\":\n",
    "                    categoryId = 11\n",
    "                elif row[5] == \"Practice not covered\":\n",
    "                    categoryId = 12\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                policySegment = ''\n",
    "                jsonData=json.loads(row[6])\n",
    "                for (k, v) in jsonData.items():\n",
    "                    for (k, v) in v.items():\n",
    "                        if k == 'selectedText':\n",
    "                            policySegment = ''.join(v)\n",
    "                \n",
    "                policySegments.append([policySegment, categoryId, row[5]])\n",
    "            #print policySegments\n",
    "            #print policySegments\n",
    "    df = pd.DataFrame(policySegments, columns = ['text', 'label', 'label_name'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDocs(dataFrame):\n",
    "    cleanNull = dataFrame[df.text != 'null'].reset_index(drop=True)\n",
    "    stop = set(stopwords.words('english'))\n",
    "    exclude = set(string.punctuation) \n",
    "    lemma = WordNetLemmatizer()\n",
    "    clean_docs = []\n",
    "    bigram_docs = []\n",
    "    for index, entry in enumerate(cleanNull['text']):\n",
    "        stop_free = \" \".join([i for i in entry.lower().split() if i not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        digit_free = [word for word in punc_free.split() if not word.isdigit() and len(word) > 2]\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in digit_free)\n",
    "        nouns = [word[0] for word in nltk.pos_tag(normalized.split()) if word[1] == 'NN' or word[1] == 'VB']\n",
    "        cleanNull.loc[index,'text_final'] = str(nouns)\n",
    "\n",
    "\t#bigram_transformer = phrases.Phrases(clean_docs)\n",
    "\t\n",
    "\t#for doc in bigram_transformer[clean_docs]:\n",
    "\t#\t\tbigram_docs.append(doc)\n",
    "    cleanEmpty = cleanNull[cleanNull.text_final != '[]']\n",
    "    return cleanEmpty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestDataset(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(Corpus):\n",
    "    Train_data, Test_data, Train_label, Test_label = train_test_split(Corpus['text_final'],Corpus['label'],test_size=0.3)\n",
    "    #Encoder = preprocessing.LabelEncoder()\n",
    "    #Train_label = Encoder.fit_transform(Train_label)\n",
    "    #Test_label = Encoder.fit_transform(Test_label)\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "    Tfidf_vect.fit(Corpus['text_final'])\n",
    "    Train_data_Tfidf = Tfidf_vect.transform(Train_data)\n",
    "    Test_data_Tfidf = Tfidf_vect.transform(Test_data)\n",
    "    \n",
    "#     print(Tfidf_vect.vocabulary_)\n",
    "    \n",
    "    # fit the training dataset on the NB classifier\n",
    "#     Naive = MultinomialNB()\n",
    "#     Naive.fit(Train_data_Tfidf,Train_label)\n",
    "#     # predict the labels on validation dataset\n",
    "#     predictions_NB = Naive.predict(Test_data_Tfidf)\n",
    "#     # Use accuracy_score function to get the accuracy\n",
    "#     print(classification_report(Test_label, predictions_NB))\n",
    "#     print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_label)*100)\n",
    "    \n",
    "    # Classifier - Algorithm - SVM\n",
    "    # fit the training dataset on the classifier\n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(Train_data_Tfidf,Train_label)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_SVM = SVM.predict(Test_data_Tfidf)\n",
    "    #print Test_data_Tfidf\n",
    "    #print predictions_SVM\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(classification_report(Test_label, predictions_SVM))\n",
    "    print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_label)*100)\n",
    "    \n",
    "    webPolicyCorpus = loadTestDataset('topic_10_only_nouns_n_verb_run_1.csv')\n",
    "    webPolicy_TFidf = Tfidf_vect.transform(webPolicyCorpus['0'])\n",
    "    webPolicyPredition = SVM.predict(webPolicy_TFidf)\n",
    "    print webPolicyPredition\n",
    "    webPolicyDf = mergeData(webPolicyCorpus, webPolicyPredition)\n",
    "    webPolicyDf.to_csv('topic_10_only_nouns_n_verb_run_1_prediction.csv', index=False)\n",
    "    \n",
    "    gdprPolicyCorpus = loadTestDataset('topic_10_gdpr_only_nouns_n_verb_run_1.csv')\n",
    "    gdprPolicy_TFidf = Tfidf_vect.transform(gdprPolicyCorpus['0'])\n",
    "    gdprPolicyPredition = SVM.predict(gdprPolicy_TFidf)\n",
    "    gdprPolicyDf = mergeData(gdprPolicyCorpus, gdprPolicyPredition)\n",
    "    gdprPolicyDf.to_csv('topic_10_gdpr_only_nouns_n_verb_run_1_prediction.csv', index=False)\n",
    "    \n",
    "    return SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLable(model, corpus):\n",
    "    print corpus\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "    webPolicy_TFidf = Tfidf_vect.transform(corpus['0'])\n",
    "    webPolicyPredition = model.predict(webPolicy_TFidf)\n",
    "    \n",
    "    return webPolicyPredition;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData(corpus, predictedResult):\n",
    "    labels = [[1, 'First Party Collection/Use'], \n",
    "              [2, 'Third Party Sharing/Collection'], \n",
    "              [3, 'User Choice/Control'], \n",
    "              [4, 'User Access, Edit and Deletion'], \n",
    "              [5, 'Data Retention'],\n",
    "              [6, 'Data Security'],\n",
    "              [7, 'Policy Change'], \n",
    "              [8, 'Do Not Track'],\n",
    "              [9, 'International and Specific Audiences'],\n",
    "              [10, 'Introductory/Generic'],\n",
    "              [11, 'Privacy contact information'],\n",
    "              [12, 'Privacy contact information']]\n",
    "    \n",
    "    dfLabel = pd.DataFrame(labels, columns=['label', 'discription'])\n",
    "    dfPredictedResult = pd.DataFrame(predictedResult)\n",
    "    dfContact = pd.concat([corpus, dfPredictedResult], axis=1)\n",
    "    dfContact.columns = ['topic_number', 'corpus', 'label'] \n",
    "    return pd.merge(dfContact, dfLabel, on='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First Party Collection/Use' 'Data Retention' 'User Choice/Control'\n",
      " 'User Access, Edit and Deletion' 'Third Party Sharing/Collection'\n",
      " 'Data Security' 'International and Specific Audiences' 'Policy Change'\n",
      " 'Do Not Track']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.90      0.73      1765\n",
      "           2       0.84      0.81      0.83      1377\n",
      "           3       0.77      0.37      0.50       497\n",
      "           4       0.88      0.07      0.13       222\n",
      "           5       0.00      0.00      0.00       110\n",
      "           6       0.95      0.69      0.80       289\n",
      "           7       0.94      0.51      0.66       166\n",
      "           8       1.00      0.16      0.27        19\n",
      "           9       0.89      0.82      0.86       251\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      4696\n",
      "   macro avg       0.77      0.48      0.53      4696\n",
      "weighted avg       0.75      0.72      0.70      4696\n",
      "\n",
      "('Naive Bayes Accuracy Score -> ', 72.38074957410562)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.84      0.75      1765\n",
      "           2       0.82      0.85      0.83      1377\n",
      "           3       0.70      0.46      0.56       497\n",
      "           4       0.71      0.41      0.52       222\n",
      "           5       0.14      0.02      0.03       110\n",
      "           6       0.93      0.80      0.86       289\n",
      "           7       0.89      0.73      0.81       166\n",
      "           8       1.00      0.84      0.91        19\n",
      "           9       0.92      0.90      0.91       251\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      4696\n",
      "   macro avg       0.76      0.65      0.69      4696\n",
      "weighted avg       0.75      0.76      0.75      4696\n",
      "\n",
      "('SVM Accuracy Score -> ', 75.8304940374787)\n",
      "[2 6 2 9 9 2 9 4 7 1]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(500)\n",
    "fileLocation = '/home/lahiru/Research/policy_analysis/data/usableprivacy/OPP-115/annotations'\n",
    "\n",
    "df = readPolicyFile(fileLocation)\n",
    "Corpus = cleanDocs(df)\n",
    "print Corpus['label_name'].unique()\n",
    "Corpus.to_csv('clean_OOP-115_policy_corpus.csv', index=False)\n",
    "model = buildModel(Corpus)\n",
    "\n",
    "# webPolicyCorpus = loadTestDataset('topic_10_only_nouns_n_verb_run_1.csv')\n",
    "# gdprPolicyCorpus = loadTestDataset('topic_10_gdpr_only_nouns_n_verb_run_1.csv')\n",
    "\n",
    "# webPolicyPrediction = predictLable(model, webPolicyCorpus)\n",
    "# gdprPolicyPrediction = predictLable(model, gdprPolicyCorpus)\n",
    "\n",
    "# mergeData(webPolicyCorpus, webPolicyPrediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
